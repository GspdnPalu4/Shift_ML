{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4149998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lego-\\AppData\\Local\\Temp\\ipykernel_19392\\3076531231.py:18: DtypeWarning: Columns (49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('shift_ml_2025_train.csv')\n",
      "C:\\Users\\lego-\\AppData\\Local\\Temp\\ipykernel_19392\\3076531231.py:201: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  X['дата_первого_займа'] = pd.to_datetime(X['дата_первого_займа'])\n"
     ]
    }
   ],
   "source": [
    "#импортируем библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Загружаем данные\n",
    "train = pd.read_csv('shift_ml_2025_train.csv')\n",
    "target = train['итоговый_статус_займа']\n",
    "test = pd.read_csv('shift_ml_2025_test.csv')\n",
    "\n",
    "train.describe()\n",
    "train.head(5)\n",
    "\n",
    "#Отбираем топ признаки при помощи RandomForestClassifier\n",
    "X = train.drop(columns=[\"id\", \"итоговый_статус_займа\"], errors='ignore') \n",
    "y = train[\"итоговый_статус_займа\"]\n",
    "\n",
    "X_num = X.select_dtypes(include=[\"number\"]).fillna(0)\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_num, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_rf, y_train_rf)\n",
    "importances = pd.Series(model.feature_importances_, index=X_num.columns)\n",
    "importances.sort_values(ascending=False)\n",
    "top_features = importances.sort_values(ascending=False).head(43).index\n",
    "\n",
    "#Оставим признаки, которые описывают хотя бы 1%\n",
    "top_features = importances.sort_values(ascending=False).head(43).index\n",
    "X = pd.concat([train[top_features], train['итоговый_статус_займа']], axis=1)\n",
    "\n",
    "# EDA / трансформации\n",
    "\n",
    "def safe_drop(df, cols):\n",
    "    return df.drop(columns=[c for c in (cols if isinstance(cols, (list,tuple)) else [cols]) if c in df.columns], errors='ignore')\n",
    "\n",
    "# удаляем коррелированные колонки\n",
    "X = safe_drop(X, ['коэфф_акционных_зачислений_в_остатке','коэфф_исходного_платежа','общий_лимит_по_возоб_счету'])\n",
    "\n",
    "# процент_счетов_без_просрочек заполним 100\n",
    "if 'процент_счетов_без_просрочек' in X.columns:\n",
    "    X['процент_счетов_без_просрочек'] = X['процент_счетов_без_просрочек'].fillna(100)\n",
    "\n",
    "# Кол-во счетов без нарушений заполним пропуски 0\n",
    "if 'кол-во_счетов_без_нарушений' in X.columns:\n",
    "    X['кол-во_счетов_без_нарушений'] = X['кол-во_счетов_без_нарушений'].fillna(0)\n",
    "\n",
    "# Логарифмируем пдн из-за скошенности\n",
    "if 'пдн' in X.columns:\n",
    "    X['пдн'] = np.log1p(abs(X['пдн']))\n",
    "\n",
    "# Прологарифмрованный Коэфф_загрузки_возобновляемого_счета из-за скошенности\n",
    "if 'коэфф_загрузки_возобновляемого_счета' in X.columns:\n",
    "    X['коэфф_загрузки_возобновляемого_счета'] = np.log1p(X['коэфф_загрузки_возобновляемого_счета'].fillna(0))\n",
    "\n",
    "# Удаляем указанные колонки, обработаем их позже\n",
    "X = safe_drop(X, ['кол-во_открытых_счетов','аннуитет'])\n",
    "if 'верхний_порог_рейтинга_заемщика' in X.columns and 'нижний_порог_рейтинга_заемщика' in X.columns:\n",
    "    X['средний_порог_рейтинга_заемщика'] = (X['верхний_порог_рейтинга_заемщика'] + X['нижний_порог_рейтинга_заемщика'])//2\n",
    "X = safe_drop(X, ['верхний_порог_рейтинга_заемщика','нижний_порог_рейтинга_заемщика'])\n",
    "X = safe_drop(X, ['кредитный_баланс_без_ипотеки'])\n",
    "\n",
    "# кредитный лимит и годовой доход \n",
    "if 'кредитный_лимит' in X.columns:\n",
    "    X['кредитный_лимит'] = X['кредитный_лимит'].fillna(X['кредитный_лимит'].median())\n",
    "if 'годовой_доход' in X.columns:\n",
    "    X['годовой_доход'] = np.log1p(X['годовой_доход'].fillna(X['годовой_доход'].median()))\n",
    "\n",
    "# Заполним пропуски\n",
    "if 'лимит_по_картам' in X.columns:\n",
    "    X['лимит_по_картам'] = X['лимит_по_картам'].fillna(X['лимит_по_картам'].median())\n",
    "\n",
    "# удаляем перечисленные колонки из-за коррелированности, сложности интерпритации\n",
    "X = safe_drop(X, ['кол-во_месяцев_с_первого_возобновляемого_счета',\n",
    "                  'суммарная_доступная_сумма_займа_по_картам',\n",
    "                  'средний_баланс_текущих_счетов',\n",
    "                  'кол-во_месяцев_с_первого_аннуитетного_счета',\n",
    "                  'соотношение_баланса_к_лимиту_по_картам',\n",
    "                  'лимит_по_картам','оборотный_баланс','общая_сумма_на_счетах'])\n",
    "\n",
    "# логарифмируем сумму займа\n",
    "if 'сумма_займа' in X.columns:\n",
    "    X['сумма_займа'] = np.log1p(X['сумма_займа'])\n",
    "\n",
    "# кол-во счетов лог\n",
    "if 'кол-во_счетов' in X.columns:\n",
    "    X['кол-во_счетов'] = np.log1p(X['кол-во_счетов'])\n",
    "\n",
    "X = safe_drop(X, ['кол-во_возобновляемых_счетов','кол-во_аннуитетных_счетов','кол-во_месяцев_с_последнего_карты'])\n",
    "\n",
    "# кол-во_мес_с_последней_заявки заполним 0 и лог\n",
    "if 'кол-во_мес_с_последней_заявки' in X.columns:\n",
    "    X['кол-во_мес_с_последней_заявки'] = X['кол-во_мес_с_последней_заявки'].fillna(0)\n",
    "    X['кол-во_мес_с_последней_заявки'] = np.log1p(X['кол-во_мес_с_последней_заявки'])\n",
    "\n",
    "# месяцы с последнего счета лог\n",
    "if 'кол-во_месяцев_с_последнего_счета' in X.columns:\n",
    "    X['кол-во_месяцев_с_последнего_счета'] = np.log1p(X['кол-во_месяцев_с_последнего_счета'].fillna(0))\n",
    "\n",
    "# Кол-во_без_нарушений/Кол-во_счетов \n",
    "if 'кол-во_счетов_без_нарушений' in X.columns and 'кол-во_счетов' in X.columns:\n",
    "    X['Кол-во_без_нарушений/Кол-во_счетов'] = np.log1p(X['кол-во_счетов_без_нарушений'])/X['кол-во_счетов']\n",
    "X = safe_drop(X, ['кол-во_открытых_возобновляемых_счетов','кол-во_счетов_без_нарушений'])\n",
    "\n",
    "# процент_счетов_без_просрочек лог и удаление (как у тебя)\n",
    "if 'процент_счетов_без_просрочек' in X.columns:\n",
    "    X['процент_счетов_без_просрочек'] = np.log1p(X['процент_счетов_без_просрочек'])\n",
    "X = safe_drop(X, ['процент_счетов_без_просрочек','кол-во_возобновляемых_счетов_с_балансом_более_0',\n",
    "                  'кол-во_карт_без_нарушений','кол-во_активных_возобновляемых_счетов',\n",
    "                  'процент_счетов_прев_75_лимита'])\n",
    "\n",
    "# заполняем пдн и другие\n",
    "if 'пдн' in X.columns:\n",
    "    X['пдн'] = X['пдн'].fillna(0)\n",
    "X = safe_drop(X, ['кол-во_карт'])\n",
    "if 'кол-во_месяцев_с_последнего_счета' in X.columns:\n",
    "    X['кол-во_месяцев_с_последнего_счета'] = X['кол-во_месяцев_с_последнего_счета'].fillna(0)\n",
    "if 'лимит_по_аннуитетным_счетам' in X.columns:\n",
    "    X['лимит_по_аннуитетным_счетам'] = X['лимит_по_аннуитетным_счетам'].fillna(0)\n",
    "    X['лимит_по_аннуитетным_счетам'] = np.log1p(X['лимит_по_аннуитетным_счетам'])\n",
    "if 'индекс_проживания' in X.columns:\n",
    "    X['индекс_проживания'] = X['индекс_проживания'].fillna(X['индекс_проживания'].median())\n",
    "if 'Кол-во_без_нарушений/Кол-во_счетов' in X.columns:\n",
    "    X['Кол-во_без_нарушений/Кол-во_счетов'] = X['Кол-во_без_нарушений/Кол-во_счетов'].fillna(0)\n",
    "\n",
    "\n",
    "if 'кол-во_месяцев_с_последней_просрочки' in X.columns:\n",
    "    X['кол-во_месяцев_с_последней_просрочки'] = X['кол-во_месяцев_с_последней_просрочки'].fillna(0)\n",
    "\n",
    "# суммарное_кол-во_счетов - Сделаем одно общее поле для большинства счетов\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "cols_to_sum = [\n",
    "    'кол-во_возоб_счетов_за_2_года',\n",
    "    'кол-во_возоб_счетов_за_год',\n",
    "    'кол-во_возобновляемых_счетов_с_балансом_более_0',\n",
    "    'кол-во_активных_возобновляемых_счетов',\n",
    "    'кол-во_открытых_счетов_за_2_года',\n",
    "    'кол-во_открытых_счетов_за_полгода',\n",
    "    'кол-во_счетов_за_посл_год'\n",
    "]\n",
    "cols_to_sum_present = [c for c in cols_to_sum if c in train.columns]\n",
    "if cols_to_sum_present:\n",
    "    scaler = MinMaxScaler()\n",
    "    _ = scaler.fit_transform(train[cols_to_sum_present])\n",
    "    train['суммарное_кол-во_счетов'] = train[cols_to_sum_present].sum(axis=1)\n",
    "\n",
    "X = pd.concat([\n",
    "    X,\n",
    "    train['суммарное_кол-во_счетов'] if 'суммарное_кол-во_счетов' in train.columns else pd.Series(0, index=X.index),\n",
    "    train['кол-во_заявок_за_полгода'].fillna(0) if 'кол-во_заявок_за_полгода' in train.columns else pd.Series(0, index=X.index),\n",
    "    train['кол-во_месяцев_с_первого_возобновляемого_счета'].fillna(0) if 'кол-во_месяцев_с_первого_возобновляемого_счета' in train.columns else pd.Series(0, index=X.index),\n",
    "    train['процент_счетов_прев_75_лимита'].fillna(0) if 'процент_счетов_прев_75_лимита' in train.columns else pd.Series(0, index=X.index)\n",
    "], axis=1)\n",
    "\n",
    "# процентная ставка fillna \n",
    "if 'процентная_ставка' in X.columns:\n",
    "    X['процентная_ставка'] = X['процентная_ставка'].fillna(X['процентная_ставка'].median())\n",
    "\n",
    "# добавляем категориальные \n",
    "categorical_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
    "X = pd.concat([X, train[categorical_cols]], axis=1)\n",
    "\n",
    "missing = X.isnull().sum().sort_values()\n",
    "missing\n",
    "\n",
    "#  преобразования даты в декады\n",
    "# срок_займа: извлекаем первую цифру\n",
    "if 'срок_займа' in X.columns:\n",
    "    X['срок_займа'] = X['срок_займа'].str.split().str[0].astype(int)\n",
    "\n",
    "# рейтинг и допрейтинг — OrdinalEncoder \n",
    "rating_order = ['А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж']\n",
    "dop_rating_order = [f\"{letter}{num}\" for letter in rating_order for num in range(1, 6)]\n",
    "# создаём отдельный энкодер enc_rating чтобы не перезаписывать переменные\n",
    "enc_rating = OrdinalEncoder(categories=[rating_order, dop_rating_order])\n",
    "if all(c in X.columns for c in ['рейтинг','допрейтинг']):\n",
    "    X[['рейтинг', 'допрейтинг']] = enc_rating.fit_transform(X[['рейтинг','допрейтинг']])\n",
    "\n",
    "# стаж — OrdinalEncoder \n",
    "if 'стаж' in X.columns:\n",
    "    X['стаж'] = X['стаж'].fillna('не указан')\n",
    "    experience_order = [['не указан','< 1 года', '1 год', '2 года', '3 года', '4 года', '5 лет', '6 лет', '7 лет', '8 лет', '9 лет', '10+ лет']]\n",
    "    enc1 = OrdinalEncoder(categories=experience_order)\n",
    "    X['стаж'] = enc1.fit_transform(X[['стаж']])\n",
    "\n",
    "# платежный график - пустой столбец с n\n",
    "X = safe_drop(X, 'платежный_график')\n",
    "\n",
    "# дата_первого_займа -> год, декада -> OrdinalEncoder \n",
    "if 'дата_первого_займа' in X.columns:\n",
    "    X['дата_первого_займа'] = pd.to_datetime(X['дата_первого_займа'])\n",
    "    X['год'] = X['дата_первого_займа'].dt.year\n",
    "    X['декада'] = (X['год'] // 10) * 10\n",
    "    X = X.dropna(subset=['декада'])\n",
    "    enc_dek = OrdinalEncoder(categories=[[1930,1940,1950,1960,1970,1980,1990,2000,2010,2020]])\n",
    "    X['декада'] = enc_dek.fit_transform(X[['декада']])\n",
    "    X = safe_drop(X, 'дата_первого_займа')\n",
    "\n",
    "# первоначальный_статус_займа - OrdinalEncoder\n",
    "if 'первоначальный_статус_займа' in X.columns:\n",
    "    enc_init = OrdinalEncoder(categories=[['а','б']])\n",
    "    X['первоначальный_статус_займа'] = enc_init.fit_transform(X[['первоначальный_статус_займа']])\n",
    "\n",
    "# удаляем пени_за_дефолт (утечка)\n",
    "X = safe_drop(X, 'пени_за_дефолт')\n",
    "\n",
    "# совокупный_статус_подтверждения_доходов_заемщиков -> fillna\n",
    "if 'совокупный_статус_подтверждения_доходов_заемщиков' in X.columns:\n",
    "    X['совокупный_статус_подтверждения_доходов_заемщиков'] = X['совокупный_статус_подтверждения_доходов_заемщиков'].fillna('Не подтвержден')\n",
    "    X['совокупный_статус_подтверждения_доходов_заемщиков'] = X['совокупный_статус_подтверждения_доходов_заемщиков'].astype(str)\n",
    "\n",
    "X = safe_drop(X, 'особая_ситуация')\n",
    "\n",
    "if 'процентная_ставка' in X.columns:\n",
    "    X = X.dropna(subset=['процентная_ставка'])\n",
    "if 'кол-во_счетов' in X.columns:\n",
    "    X = X.dropna(subset=['кол-во_счетов'])\n",
    "\n",
    "# бинарный индикатор просрочки и лог суммы просрочек\n",
    "if 'сумма_выплат_по_просрочкам' in X.columns:\n",
    "    X['бинарные_идентификатор_суммы_просрочки'] = (X['сумма_выплат_по_просрочкам'] > 0).astype(int)\n",
    "    X['сумма_выплат_по_просрочкам'] = np.log1p(X['сумма_выплат_по_просрочкам'].fillna(0))\n",
    "\n",
    "# отделяем y и удаляем таргет столбец\n",
    "if 'итоговый_статус_займа' in X.columns:\n",
    "    y = X['итоговый_статус_займа']\n",
    "    X = X.drop('итоговый_статус_займа', axis=1)\n",
    "\n",
    "# OneHot \n",
    "# Владение жильем\n",
    "encoder_vl = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'владение_жильем' in X.columns:\n",
    "    encoded_array = encoder_vl.fit_transform(X[['владение_жильем']])\n",
    "    encoded_cols = encoder_vl.get_feature_names_out(['владение_жильем'])\n",
    "    train_encoded = pd.DataFrame(encoded_array, columns=encoded_cols, index=X.index)\n",
    "    X = pd.concat([X, train_encoded], axis=1)\n",
    "    X = X.drop('владение_жильем', axis=1)\n",
    "\n",
    "# Цель займа \n",
    "encoder_goal = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'цель_займа' in X.columns:\n",
    "    encoded_array = encoder_goal.fit_transform(X[['цель_займа']])\n",
    "    encoded_cols = encoder_goal.get_feature_names_out(['цель_займа'])\n",
    "    train_encoded1 = pd.DataFrame(encoded_array, columns=encoded_cols, index=X.index)\n",
    "    X = pd.concat([X, train_encoded1], axis=1)\n",
    "    X = X.drop('цель_займа', axis=1)\n",
    "\n",
    "# Подтвержден ли доход\n",
    "encoder5 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'подтвержден_ли_доход' in X.columns:\n",
    "    encoded_array5 = encoder5.fit_transform(X[['подтвержден_ли_доход']])\n",
    "    encoded_cols5 = encoder5.get_feature_names_out(['подтвержден_ли_доход'])\n",
    "    train_encoded5 = pd.DataFrame(encoded_array5, columns=encoded_cols5, index=X.index)\n",
    "    X = pd.concat([X, train_encoded5], axis=1)\n",
    "    X = X.drop('подтвержден_ли_доход', axis=1)\n",
    "\n",
    "# Совокупный статус подтверждения доходов\n",
    "encoder3 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'совокупный_статус_подтверждения_доходов_заемщиков' in X.columns:\n",
    "    encoded_array3 = encoder3.fit_transform(X[['совокупный_статус_подтверждения_доходов_заемщиков']])\n",
    "    encoded_cols3 = encoder3.get_feature_names_out(['совокупный_статус_подтверждения_доходов_заемщиков'])\n",
    "    train_encoded3 = pd.DataFrame(encoded_array3, columns=encoded_cols3, index=X.index)\n",
    "    X = pd.concat([X, train_encoded3], axis=1)\n",
    "    X = X.drop('совокупный_статус_подтверждения_доходов_заемщиков', axis=1)\n",
    "\n",
    "# Тип предоставления кредита\n",
    "encoder4 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'тип_предоставления_кредита' in X.columns:\n",
    "    encoded_array4 = encoder4.fit_transform(X[['тип_предоставления_кредита']])\n",
    "    encoded_cols4 = encoder4.get_feature_names_out(['тип_предоставления_кредита'])\n",
    "    train_encoded4 = pd.DataFrame(encoded_array4, columns=encoded_cols4, index=X.index)\n",
    "    X = pd.concat([X, train_encoded4], axis=1)\n",
    "    X = X.drop('тип_предоставления_кредита', axis=1)\n",
    "\n",
    "# пос_стоп_фактор\n",
    "encoder6 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'пос_стоп_фактор' in X.columns:\n",
    "    encoded_array6 = encoder6.fit_transform(X[['пос_стоп_фактор']])\n",
    "    encoded_cols6 = encoder6.get_feature_names_out(['пос_стоп_фактор'])\n",
    "    train_encoded6 = pd.DataFrame(encoded_array6, columns=encoded_cols6, index=X.index)\n",
    "    X = pd.concat([X, train_encoded6], axis=1)\n",
    "    X = X.drop('пос_стоп_фактор', axis=1)\n",
    "\n",
    "# юридический_статус\n",
    "encoder7 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'юридический_статус' in X.columns:\n",
    "    encoded_array7 = encoder7.fit_transform(X[['юридический_статус']])\n",
    "    encoded_cols7 = encoder7.get_feature_names_out(['юридический_статус'])\n",
    "    train_encoded7 = pd.DataFrame(encoded_array7, columns=encoded_cols7, index=X.index)\n",
    "    X = pd.concat([X, train_encoded7], axis=1)\n",
    "    X = X.drop('юридический_статус', axis=1)\n",
    "\n",
    "# тип_займа\n",
    "encoder2 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'тип_займа' in X.columns:\n",
    "    encoded_array2 = encoder2.fit_transform(X[['тип_займа']])\n",
    "    encoded_cols2 = encoder2.get_feature_names_out(['тип_займа'])\n",
    "    train_encoded2 = pd.DataFrame(encoded_array2, columns=encoded_cols2, index=X.index)\n",
    "    X = pd.concat([X, train_encoded2], axis=1)\n",
    "    X = X.drop('тип_займа', axis=1)\n",
    "\n",
    "# новые колонки - cмотрим комбинационные зависимости\n",
    "new_cols = {}\n",
    "if 'кол-во_ипотек' in train.columns:\n",
    "    new_cols['log_ипотек'] = np.log1p(train['кол-во_ипотек'])\n",
    "if 'кредитный_баланс_без_ипотеки' in train.columns:\n",
    "    new_cols['log_кредит_без_ипотеки'] = np.log1p(train['кредитный_баланс_без_ипотеки'])\n",
    "if 'аннуитет' in train.columns:\n",
    "    new_cols['log_аннуитет'] = np.log1p(train['аннуитет'])\n",
    "if all(c in X.columns for c in ['процентная_ставка','срок_займа','сумма_займа']):\n",
    "    new_cols['процент_ставка_срок_сумма'] = X['процентная_ставка'] * X['срок_займа'] * X['сумма_займа']\n",
    "if 'грейд_на_детерминаторе' in train.columns:\n",
    "    new_cols['грейд_на_детерминаторе'] = train['грейд_на_детерминаторе']\n",
    "if all(c in X.columns for c in ['годовой_доход','сумма_займа']):\n",
    "    new_cols['доход_к_займу'] = X['годовой_доход'] / X['сумма_займа'].replace(0, np.nan)\n",
    "\n",
    "if new_cols:\n",
    "    X = pd.concat([X, pd.DataFrame(new_cols, index=X.index)], axis=1)\n",
    "if 'процентная_ставка' in X.columns:\n",
    "    X = X.dropna(subset=['процентная_ставка'])\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "missing=X.isnull().sum()\n",
    "missing\n",
    "X['log_ипотек']=X['log_ипотек'].fillna(X['log_ипотек'].median())\n",
    "X['log_кредит_без_ипотеки']=X['log_кредит_без_ипотеки'].fillna(X['log_кредит_без_ипотеки'].median())\n",
    "X['кол-во_месяцев_с_последней_карты']=X['кол-во_месяцев_с_последней_карты'].fillna(X['кол-во_месяцев_с_последней_карты'].median())\n",
    "X['кол-во_месяцев_с_последнего_возобновляемого_счета']=X['кол-во_месяцев_с_последнего_возобновляемого_счета'].fillna(X['кол-во_месяцев_с_последнего_возобновляемого_счета'].median())\n",
    "X['кол-во_открытых_счетов_за_2_года']=X['кол-во_открытых_счетов_за_2_года'].fillna(X['кол-во_открытых_счетов_за_2_года'].median())\n",
    "# ====== Target encoding региона и профессии как у тебя (mapping из X_R -> X_test) ======\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_R = pd.concat([X_train_full, y_train_full], axis=1)\n",
    "\n",
    "#вычисляем mean по региону на X_R и мапим на X_train_full и X_test_full\n",
    "global_mean = X_R['итоговый_статус_займа'].mean()\n",
    "region_means = X_R.groupby('регион')['итоговый_статус_займа'].mean() if 'регион' in X_R.columns else pd.Series()\n",
    "prof_mean = X_R.groupby('профессия_заемщика')['итоговый_статус_займа'].mean() if 'профессия_заемщика' in X_R.columns else pd.Series()\n",
    "\n",
    "if 'регион' in X_train_full.columns:\n",
    "    X_train_full['регион_target_encoded'] = X_train_full['регион'].map(region_means)\n",
    "    X_test_full['регион_target_encoded'] = X_test_full['регион'].map(region_means).fillna(global_mean)\n",
    "    region_counts = X_R['регион'].value_counts()\n",
    "    X_train_full['регион_freq_encoded'] = X_train_full['регион'].map(region_counts)\n",
    "    X_test_full['регион_freq_encoded'] = X_test_full['регион'].map(region_counts).fillna(0)\n",
    "    X_train_full = X_train_full.drop('регион', axis=1)\n",
    "    X_test_full = X_test_full.drop('регион', axis=1)\n",
    "if 'профессия_заемщика' in X_train_full.columns:\n",
    "    X_train_full = X_train_full.drop('профессия_заемщика', axis=1)\n",
    "    X_test_full = X_test_full.drop('профессия_заемщика', axis=1)\n",
    "#preprocessor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "numeric_cols = X_train_full.select_dtypes(include=['int64','float64','int32']).columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), numeric_cols),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Применяем преобразования\n",
    "X_train_scaled = preprocessor.fit_transform(X_train_full)\n",
    "X_test_scaled = preprocessor.transform(X_test_full)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85f3f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7167753\tbest: 0.7167753 (0)\ttotal: 167ms\tremaining: 22m 15s\n",
      "100:\ttest: 0.7422874\tbest: 0.7422874 (100)\ttotal: 1.13s\tremaining: 1m 28s\n",
      "200:\ttest: 0.7462976\tbest: 0.7462976 (200)\ttotal: 2.09s\tremaining: 1m 21s\n",
      "300:\ttest: 0.7483369\tbest: 0.7483369 (300)\ttotal: 3.03s\tremaining: 1m 17s\n",
      "400:\ttest: 0.7498326\tbest: 0.7498326 (400)\ttotal: 3.97s\tremaining: 1m 15s\n",
      "500:\ttest: 0.7509471\tbest: 0.7509471 (500)\ttotal: 4.92s\tremaining: 1m 13s\n",
      "600:\ttest: 0.7518557\tbest: 0.7518557 (600)\ttotal: 5.84s\tremaining: 1m 11s\n",
      "700:\ttest: 0.7525711\tbest: 0.7525711 (700)\ttotal: 6.8s\tremaining: 1m 10s\n",
      "800:\ttest: 0.7531831\tbest: 0.7531831 (800)\ttotal: 7.74s\tremaining: 1m 9s\n",
      "900:\ttest: 0.7536697\tbest: 0.7536697 (900)\ttotal: 8.66s\tremaining: 1m 8s\n",
      "1000:\ttest: 0.7540881\tbest: 0.7540881 (1000)\ttotal: 9.58s\tremaining: 1m 6s\n",
      "1100:\ttest: 0.7544754\tbest: 0.7544754 (1100)\ttotal: 10.5s\tremaining: 1m 5s\n",
      "1200:\ttest: 0.7548474\tbest: 0.7548474 (1200)\ttotal: 11.5s\tremaining: 1m 4s\n",
      "1300:\ttest: 0.7551461\tbest: 0.7551461 (1300)\ttotal: 12.4s\tremaining: 1m 3s\n",
      "1400:\ttest: 0.7554200\tbest: 0.7554200 (1400)\ttotal: 13.3s\tremaining: 1m 2s\n",
      "1500:\ttest: 0.7556791\tbest: 0.7556791 (1500)\ttotal: 14.3s\tremaining: 1m 1s\n",
      "1600:\ttest: 0.7558834\tbest: 0.7558834 (1600)\ttotal: 15.2s\tremaining: 1m\n",
      "1700:\ttest: 0.7560820\tbest: 0.7560820 (1700)\ttotal: 16.2s\tremaining: 59.9s\n",
      "1800:\ttest: 0.7562689\tbest: 0.7562689 (1800)\ttotal: 17.1s\tremaining: 58.9s\n",
      "1900:\ttest: 0.7564081\tbest: 0.7564081 (1899)\ttotal: 18s\tremaining: 57.9s\n",
      "2000:\ttest: 0.7565952\tbest: 0.7565952 (2000)\ttotal: 19s\tremaining: 56.8s\n",
      "2100:\ttest: 0.7567388\tbest: 0.7567388 (2100)\ttotal: 19.9s\tremaining: 55.8s\n",
      "2200:\ttest: 0.7568780\tbest: 0.7568780 (2200)\ttotal: 20.8s\tremaining: 54.8s\n",
      "2300:\ttest: 0.7569998\tbest: 0.7569998 (2300)\ttotal: 21.7s\tremaining: 53.8s\n",
      "2400:\ttest: 0.7571446\tbest: 0.7571456 (2397)\ttotal: 22.7s\tremaining: 52.8s\n",
      "2500:\ttest: 0.7572773\tbest: 0.7572773 (2500)\ttotal: 23.6s\tremaining: 51.8s\n",
      "2600:\ttest: 0.7573751\tbest: 0.7573751 (2600)\ttotal: 24.5s\tremaining: 50.8s\n",
      "2700:\ttest: 0.7574865\tbest: 0.7574865 (2700)\ttotal: 25.4s\tremaining: 49.8s\n",
      "2800:\ttest: 0.7575925\tbest: 0.7575925 (2800)\ttotal: 26.3s\tremaining: 48.8s\n",
      "2900:\ttest: 0.7576779\tbest: 0.7576779 (2900)\ttotal: 27.2s\tremaining: 47.9s\n",
      "3000:\ttest: 0.7577344\tbest: 0.7577344 (3000)\ttotal: 28.1s\tremaining: 46.8s\n",
      "3100:\ttest: 0.7578073\tbest: 0.7578081 (3099)\ttotal: 29s\tremaining: 45.9s\n",
      "3200:\ttest: 0.7578821\tbest: 0.7578837 (3198)\ttotal: 29.9s\tremaining: 44.9s\n",
      "3300:\ttest: 0.7579598\tbest: 0.7579598 (3299)\ttotal: 30.9s\tremaining: 43.9s\n",
      "3400:\ttest: 0.7580058\tbest: 0.7580059 (3397)\ttotal: 31.8s\tremaining: 43s\n",
      "3500:\ttest: 0.7580470\tbest: 0.7580470 (3500)\ttotal: 32.7s\tremaining: 42s\n",
      "3600:\ttest: 0.7580991\tbest: 0.7580991 (3600)\ttotal: 33.6s\tremaining: 41.1s\n",
      "3700:\ttest: 0.7581370\tbest: 0.7581378 (3692)\ttotal: 34.6s\tremaining: 40.2s\n",
      "3800:\ttest: 0.7581701\tbest: 0.7581722 (3790)\ttotal: 35.5s\tremaining: 39.3s\n",
      "3900:\ttest: 0.7582132\tbest: 0.7582132 (3900)\ttotal: 36.4s\tremaining: 38.3s\n",
      "4000:\ttest: 0.7582401\tbest: 0.7582401 (4000)\ttotal: 37.4s\tremaining: 37.3s\n",
      "4100:\ttest: 0.7582727\tbest: 0.7582738 (4095)\ttotal: 38.3s\tremaining: 36.4s\n",
      "4200:\ttest: 0.7583176\tbest: 0.7583201 (4194)\ttotal: 39.2s\tremaining: 35.5s\n",
      "4300:\ttest: 0.7583618\tbest: 0.7583618 (4300)\ttotal: 40.1s\tremaining: 34.5s\n",
      "4400:\ttest: 0.7584113\tbest: 0.7584113 (4400)\ttotal: 41s\tremaining: 33.6s\n",
      "4500:\ttest: 0.7584424\tbest: 0.7584424 (4500)\ttotal: 42s\tremaining: 32.6s\n",
      "4600:\ttest: 0.7584869\tbest: 0.7584869 (4600)\ttotal: 42.9s\tremaining: 31.7s\n",
      "4700:\ttest: 0.7585233\tbest: 0.7585241 (4695)\ttotal: 43.8s\tremaining: 30.8s\n",
      "4800:\ttest: 0.7585781\tbest: 0.7585784 (4799)\ttotal: 44.7s\tremaining: 29.8s\n",
      "4900:\ttest: 0.7586123\tbest: 0.7586123 (4900)\ttotal: 45.7s\tremaining: 28.9s\n",
      "5000:\ttest: 0.7586447\tbest: 0.7586447 (5000)\ttotal: 46.6s\tremaining: 27.9s\n",
      "5100:\ttest: 0.7586683\tbest: 0.7586683 (5100)\ttotal: 47.5s\tremaining: 27s\n",
      "5200:\ttest: 0.7586862\tbest: 0.7586866 (5198)\ttotal: 48.4s\tremaining: 26.1s\n",
      "5300:\ttest: 0.7586905\tbest: 0.7586905 (5300)\ttotal: 49.3s\tremaining: 25.1s\n",
      "5400:\ttest: 0.7587136\tbest: 0.7587141 (5396)\ttotal: 50.2s\tremaining: 24.2s\n",
      "5500:\ttest: 0.7587321\tbest: 0.7587369 (5481)\ttotal: 51.2s\tremaining: 23.2s\n",
      "5600:\ttest: 0.7587624\tbest: 0.7587627 (5593)\ttotal: 52.1s\tremaining: 22.3s\n",
      "5700:\ttest: 0.7587740\tbest: 0.7587775 (5688)\ttotal: 53s\tremaining: 21.4s\n",
      "5800:\ttest: 0.7587928\tbest: 0.7587953 (5784)\ttotal: 54s\tremaining: 20.5s\n",
      "5900:\ttest: 0.7588150\tbest: 0.7588179 (5895)\ttotal: 55s\tremaining: 19.6s\n",
      "6000:\ttest: 0.7588328\tbest: 0.7588345 (5999)\ttotal: 55.9s\tremaining: 18.6s\n",
      "6100:\ttest: 0.7588391\tbest: 0.7588465 (6075)\ttotal: 56.9s\tremaining: 17.7s\n",
      "6200:\ttest: 0.7588678\tbest: 0.7588693 (6199)\ttotal: 57.8s\tremaining: 16.8s\n",
      "6300:\ttest: 0.7588905\tbest: 0.7588922 (6295)\ttotal: 58.8s\tremaining: 15.8s\n",
      "6400:\ttest: 0.7589064\tbest: 0.7589087 (6398)\ttotal: 59.7s\tremaining: 14.9s\n",
      "6500:\ttest: 0.7589217\tbest: 0.7589226 (6498)\ttotal: 1m\tremaining: 14s\n",
      "6600:\ttest: 0.7589288\tbest: 0.7589324 (6571)\ttotal: 1m 1s\tremaining: 13.1s\n",
      "6700:\ttest: 0.7589381\tbest: 0.7589381 (6627)\ttotal: 1m 2s\tremaining: 12.1s\n",
      "6800:\ttest: 0.7589527\tbest: 0.7589540 (6765)\ttotal: 1m 3s\tremaining: 11.2s\n",
      "6900:\ttest: 0.7589749\tbest: 0.7589756 (6883)\ttotal: 1m 4s\tremaining: 10.3s\n",
      "7000:\ttest: 0.7589769\tbest: 0.7589800 (6947)\ttotal: 1m 5s\tremaining: 9.34s\n",
      "7100:\ttest: 0.7589845\tbest: 0.7589866 (7093)\ttotal: 1m 6s\tremaining: 8.41s\n",
      "7200:\ttest: 0.7589854\tbest: 0.7589871 (7191)\ttotal: 1m 7s\tremaining: 7.48s\n",
      "bestTest = 0.7589870691\n",
      "bestIteration = 7191\n",
      "Shrink model to first 7192 iterations.\n",
      "ROC AUC: 0.7590\n"
     ]
    }
   ],
   "source": [
    "# выбираем CatBoostClassifer как модель с наибольшей описательной способностью по ROC AUC\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=8000,\n",
    "    learning_rate=0.03,\n",
    "    depth=5,\n",
    "    loss_function='Logloss',\n",
    "    random_state=42,\n",
    "    eval_metric='AUC',\n",
    "    verbose=100,\n",
    "    auto_class_weights='Balanced',\n",
    "    task_type='GPU'\n",
    ")\n",
    "model.fit(\n",
    "    X_train_scaled, y_train_full,\n",
    "    eval_set=(X_test_scaled, y_test_full),\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=100,\n",
    ")\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test_full, y_pred_proba)\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f292d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lego-\\AppData\\Local\\Temp\\ipykernel_19392\\2025430610.py:131: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  X['дата_первого_займа'] = pd.to_datetime(X['дата_первого_займа'])\n"
     ]
    }
   ],
   "source": [
    "#Преобразуем тестовые данные \n",
    "X = test[top_features]\n",
    "\n",
    "\n",
    "X = safe_drop(X, ['коэфф_акционных_зачислений_в_остатке','коэфф_исходного_платежа','общий_лимит_по_возоб_счету'])\n",
    "\n",
    "\n",
    "if 'процент_счетов_без_просрочек' in X.columns:\n",
    "    X['процент_счетов_без_просрочек'] = X['процент_счетов_без_просрочек'].fillna(100)\n",
    "\n",
    "# Кол-во счетов без нарушений заполним пропуски 0\n",
    "if 'кол-во_счетов_без_нарушений' in X.columns:\n",
    "    X['кол-во_счетов_без_нарушений'] = X['кол-во_счетов_без_нарушений'].fillna(0)\n",
    "\n",
    "if 'пдн' in X.columns:\n",
    "    X['пдн'] = np.log1p(abs(X['пдн']))\n",
    "\n",
    "if 'коэфф_загрузки_возобновляемого_счета' in X.columns:\n",
    "    X['коэфф_загрузки_возобновляемого_счета'] = np.log1p(X['коэфф_загрузки_возобновляемого_счета'].fillna(0))\n",
    "\n",
    "X = safe_drop(X, ['кол-во_открытых_счетов','аннуитет'])\n",
    "if 'верхний_порог_рейтинга_заемщика' in X.columns and 'нижний_порог_рейтинга_заемщика' in X.columns:\n",
    "    X['средний_порог_рейтинга_заемщика'] = (X['верхний_порог_рейтинга_заемщика'] + X['нижний_порог_рейтинга_заемщика'])//2\n",
    "X = safe_drop(X, ['верхний_порог_рейтинга_заемщика','нижний_порог_рейтинга_заемщика'])\n",
    "\n",
    "if 'кредитный_лимит' in X.columns:\n",
    "    X['кредитный_лимит'] = X['кредитный_лимит'].fillna(X['кредитный_лимит'].median())\n",
    "if 'годовой_доход' in X.columns:\n",
    "    X['годовой_доход'] = np.log1p(X['годовой_доход'].fillna(X['годовой_доход'].median()))\n",
    "\n",
    "if 'лимит_по_картам' in X.columns:\n",
    "    X['лимит_по_картам'] = X['лимит_по_картам'].fillna(X['лимит_по_картам'].median())\n",
    "\n",
    "X = safe_drop(X, ['кол-во_месяцев_с_первого_возобновляемого_счета',\n",
    "                  'суммарная_доступная_сумма_займа_по_картам',\n",
    "                  'средний_баланс_текущих_счетов',\n",
    "                  'кол-во_месяцев_с_первого_аннуитетного_счета',\n",
    "                  'соотношение_баланса_к_лимиту_по_картам',\n",
    "                  'лимит_по_картам','оборотный_баланс','общая_сумма_на_счетах'])\n",
    "\n",
    "if 'сумма_займа' in X.columns:\n",
    "    X['сумма_займа'] = np.log1p(X['сумма_займа'])\n",
    "\n",
    "if 'кол-во_счетов' in X.columns:\n",
    "    X['кол-во_счетов'] = np.log1p(X['кол-во_счетов'])\n",
    "\n",
    "X = safe_drop(X, ['кол-во_возобновляемых_счетов','кол-во_аннуитетных_счетов','кол-во_месяцев_с_последнего_карты'])\n",
    "\n",
    "if 'кол-во_мес_с_последней_заявки' in X.columns:\n",
    "    X['кол-во_мес_с_последней_заявки'] = X['кол-во_мес_с_последней_заявки'].fillna(0)\n",
    "    X['кол-во_мес_с_последней_заявки'] = np.log1p(X['кол-во_мес_с_последней_заявки'])\n",
    "\n",
    "if 'кол-во_месяцев_с_последнего_счета' in X.columns:\n",
    "    X['кол-во_месяцев_с_последнего_счета'] = np.log1p(X['кол-во_месяцев_с_последнего_счета'].fillna(0))\n",
    "\n",
    "if 'кол-во_счетов_без_нарушений' in X.columns and 'кол-во_счетов' in X.columns:\n",
    "    X['Кол-во_без_нарушений/Кол-во_счетов'] = np.log1p(X['кол-во_счетов_без_нарушений'])/X['кол-во_счетов']\n",
    "X = safe_drop(X, ['кол-во_открытых_возобновляемых_счетов','кол-во_счетов_без_нарушений'])\n",
    "\n",
    "if 'процент_счетов_без_просрочек' in X.columns:\n",
    "    X['процент_счетов_без_просрочек'] = np.log1p(X['процент_счетов_без_просрочек'])\n",
    "X = safe_drop(X, ['процент_счетов_без_просрочек','кол-во_возобновляемых_счетов_с_балансом_более_0',\n",
    "                  'кол-во_карт_без_нарушений','кол-во_активных_возобновляемых_счетов',\n",
    "                  'процент_счетов_прев_75_лимита'])\n",
    "\n",
    "if 'пдн' in X.columns:\n",
    "    X['пдн'] = X['пдн'].fillna(0)\n",
    "X = safe_drop(X, ['кол-во_карт'])\n",
    "if 'кол-во_месяцев_с_последнего_счета' in X.columns:\n",
    "    X['кол-во_месяцев_с_последнего_счета'] = X['кол-во_месяцев_с_последнего_счета'].fillna(0)\n",
    "if 'лимит_по_аннуитетным_счетам' in X.columns:\n",
    "    X['лимит_по_аннуитетным_счетам'] = X['лимит_по_аннуитетным_счетам'].fillna(0)\n",
    "    X['лимит_по_аннуитетным_счетам'] = np.log1p(X['лимит_по_аннуитетным_счетам'])\n",
    "if 'индекс_проживания' in X.columns:\n",
    "    X['индекс_проживания'] = X['индекс_проживания'].fillna(X['индекс_проживания'].median())\n",
    "if 'Кол-во_без_нарушений/Кол-во_счетов' in X.columns:\n",
    "    X['Кол-во_без_нарушений/Кол-во_счетов'] = X['Кол-во_без_нарушений/Кол-во_счетов'].fillna(0)\n",
    "if 'кол-во_месяцев_с_последней_просрочки' in X.columns:\n",
    "    X['кол-во_месяцев_с_последней_просрочки'] = X['кол-во_месяцев_с_последней_просрочки'].fillna(0)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "cols_to_sum = [\n",
    "    'кол-во_возоб_счетов_за_2_года',\n",
    "    'кол-во_возоб_счетов_за_год',\n",
    "    'кол-во_возобновляемых_счетов_с_балансом_более_0',\n",
    "    'кол-во_активных_возобновляемых_счетов',\n",
    "    'кол-во_открытых_счетов_за_2_года',\n",
    "    'кол-во_открытых_счетов_за_полгода',\n",
    "    'кол-во_счетов_за_посл_год'\n",
    "]\n",
    "cols_to_sum_present = [c for c in cols_to_sum if c in test.columns]\n",
    "if cols_to_sum_present:\n",
    "    scaler=MinMaxScaler()\n",
    "    _ = scaler.fit_transform(test[cols_to_sum_present])\n",
    "    test['суммарное_кол-во_счетов'] = test[cols_to_sum_present].sum(axis=1)\n",
    "X = pd.concat([\n",
    "    X,\n",
    "    test['суммарное_кол-во_счетов'] if 'суммарное_кол-во_счетов' in test.columns else pd.Series(0, index=X.index),\n",
    "    test['кол-во_заявок_за_полгода'].fillna(0) if 'кол-во_заявок_за_полгода' in test.columns else pd.Series(0, index=X.index),\n",
    "    test['кол-во_месяцев_с_первого_возобновляемого_счета'].fillna(0) if 'кол-во_месяцев_с_первого_возобновляемого_счета' in test.columns else pd.Series(0, index=X.index),\n",
    "    test['процент_счетов_прев_75_лимита'].fillna(0) if 'процент_счетов_прев_75_лимита' in test.columns else pd.Series(0, index=X.index)\n",
    "], axis=1)\n",
    "\n",
    "if 'процентная_ставка' in X.columns:\n",
    "    X['процентная_ставка'] = X['процентная_ставка'].fillna(X['процентная_ставка'].median())\n",
    "\n",
    "categorical_cols = test.select_dtypes(include=['object']).columns.tolist()\n",
    "X = pd.concat([X, test[categorical_cols]], axis=1)\n",
    "\n",
    "missing = X.isnull().sum().sort_values()\n",
    "missing\n",
    "\n",
    "if 'срок_займа' in X.columns:\n",
    "    X['срок_займа'] = X['срок_займа'].str.split().str[0].astype(int)\n",
    "\n",
    "rating_order = ['А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж']\n",
    "dop_rating_order = [f\"{letter}{num}\" for letter in rating_order for num in range(1, 6)]\n",
    "enc_rating = OrdinalEncoder(categories=[rating_order, dop_rating_order])\n",
    "if all(c in X.columns for c in ['рейтинг','допрейтинг']):\n",
    "    X[['рейтинг', 'допрейтинг']] = enc_rating.fit_transform(X[['рейтинг','допрейтинг']])\n",
    "\n",
    "if 'стаж' in X.columns:\n",
    "    X['стаж'] = X['стаж'].fillna('не указан')\n",
    "    experience_order = [['не указан','< 1 года', '1 год', '2 года', '3 года', '4 года', '5 лет', '6 лет', '7 лет', '8 лет', '9 лет', '10+ лет']]\n",
    "    enc1 = OrdinalEncoder(categories=experience_order)\n",
    "    X['стаж'] = enc1.fit_transform(X[['стаж']])\n",
    "\n",
    "X = safe_drop(X, 'платежный_график')\n",
    "\n",
    "if 'дата_первого_займа' in X.columns:\n",
    "    X['дата_первого_займа'] = pd.to_datetime(X['дата_первого_займа'])\n",
    "    X['год'] = X['дата_первого_займа'].dt.year\n",
    "    X['декада'] = (X['год'] // 10) * 10\n",
    "\n",
    "    enc_dek = OrdinalEncoder(categories=[[1930,1940,1950,1960,1970,1980,1990,2000,2010,2020]])\n",
    "    X['декада'] = enc_dek.fit_transform(X[['декада']])\n",
    "    X = safe_drop(X, 'дата_первого_займа')\n",
    "\n",
    "if 'первоначальный_статус_займа' in X.columns:\n",
    "    enc_init = OrdinalEncoder(categories=[['а','б']])\n",
    "    X['первоначальный_статус_займа'] = enc_init.fit_transform(X[['первоначальный_статус_займа']])\n",
    "\n",
    "X = safe_drop(X, 'пени_за_дефолт')\n",
    "\n",
    "if 'совокупный_статус_подтверждения_доходов_заемщиков' in X.columns:\n",
    "    X['совокупный_статус_подтверждения_доходов_заемщиков'] = X['совокупный_статус_подтверждения_доходов_заемщиков'].fillna('Не подтвержден')\n",
    "    X['совокупный_статус_подтверждения_доходов_заемщиков'] = X['совокупный_статус_подтверждения_доходов_заемщиков'].astype(str)\n",
    "\n",
    "X = safe_drop(X, 'особая_ситуация')\n",
    "\n",
    "if 'процентная_ставка' in X.columns:\n",
    "    X = X.dropna(subset=['процентная_ставка'])\n",
    "\n",
    "if 'сумма_выплат_по_просрочкам' in X.columns:\n",
    "    X['бинарные_идентификатор_суммы_просрочки'] = (X['сумма_выплат_по_просрочкам'] > 0).astype(int)\n",
    "    X['сумма_выплат_по_просрочкам'] = np.log1p(X['сумма_выплат_по_просрочкам'].fillna(0))\n",
    "\n",
    "if 'итоговый_статус_займа' in X.columns:\n",
    "    y = X['итоговый_статус_займа']\n",
    "    X = X.drop('итоговый_статус_займа', axis=1)\n",
    "\n",
    "\n",
    "encoder_vl = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'владение_жильем' in X.columns:\n",
    "    encoded_array = encoder_vl.fit_transform(X[['владение_жильем']])\n",
    "    encoded_cols = encoder_vl.get_feature_names_out(['владение_жильем'])\n",
    "    train_encoded = pd.DataFrame(encoded_array, columns=encoded_cols, index=X.index)\n",
    "    X = pd.concat([X, train_encoded], axis=1)\n",
    "    X = X.drop('владение_жильем', axis=1)\n",
    "\n",
    "encoder_goal = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'цель_займа' in X.columns:\n",
    "    encoded_array = encoder_goal.fit_transform(X[['цель_займа']])\n",
    "    encoded_cols = encoder_goal.get_feature_names_out(['цель_займа'])\n",
    "    train_encoded1 = pd.DataFrame(encoded_array, columns=encoded_cols, index=X.index)\n",
    "    X = pd.concat([X, train_encoded1], axis=1)\n",
    "    X = X.drop('цель_займа', axis=1)\n",
    "\n",
    "encoder5 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'подтвержден_ли_доход' in X.columns:\n",
    "    encoded_array5 = encoder5.fit_transform(X[['подтвержден_ли_доход']])\n",
    "    encoded_cols5 = encoder5.get_feature_names_out(['подтвержден_ли_доход'])\n",
    "    train_encoded5 = pd.DataFrame(encoded_array5, columns=encoded_cols5, index=X.index)\n",
    "    X = pd.concat([X, train_encoded5], axis=1)\n",
    "    X = X.drop('подтвержден_ли_доход', axis=1)\n",
    "\n",
    "encoder3 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'совокупный_статус_подтверждения_доходов_заемщиков' in X.columns:\n",
    "    encoded_array3 = encoder3.fit_transform(X[['совокупный_статус_подтверждения_доходов_заемщиков']])\n",
    "    encoded_cols3 = encoder3.get_feature_names_out(['совокупный_статус_подтверждения_доходов_заемщиков'])\n",
    "    train_encoded3 = pd.DataFrame(encoded_array3, columns=encoded_cols3, index=X.index)\n",
    "    X = pd.concat([X, train_encoded3], axis=1)\n",
    "    X = X.drop('совокупный_статус_подтверждения_доходов_заемщиков', axis=1)\n",
    "\n",
    "encoder4 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'тип_предоставления_кредита' in X.columns:\n",
    "    encoded_array4 = encoder4.fit_transform(X[['тип_предоставления_кредита']])\n",
    "    encoded_cols4 = encoder4.get_feature_names_out(['тип_предоставления_кредита'])\n",
    "    train_encoded4 = pd.DataFrame(encoded_array4, columns=encoded_cols4, index=X.index)\n",
    "    X = pd.concat([X, train_encoded4], axis=1)\n",
    "    X = X.drop('тип_предоставления_кредита', axis=1)\n",
    "\n",
    "encoder6 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'пос_стоп_фактор' in X.columns:\n",
    "    encoded_array6 = encoder6.fit_transform(X[['пос_стоп_фактор']])\n",
    "    encoded_cols6 = encoder6.get_feature_names_out(['пос_стоп_фактор'])\n",
    "    train_encoded6 = pd.DataFrame(encoded_array6, columns=encoded_cols6, index=X.index)\n",
    "    X = pd.concat([X, train_encoded6], axis=1)\n",
    "    X = X.drop('пос_стоп_фактор', axis=1)\n",
    "\n",
    "encoder7 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'юридический_статус' in X.columns:\n",
    "    encoded_array7 = encoder7.fit_transform(X[['юридический_статус']])\n",
    "    encoded_cols7 = encoder7.get_feature_names_out(['юридический_статус'])\n",
    "    train_encoded7 = pd.DataFrame(encoded_array7, columns=encoded_cols7, index=X.index)\n",
    "    X = pd.concat([X, train_encoded7], axis=1)\n",
    "    X = X.drop('юридический_статус', axis=1)\n",
    "\n",
    "encoder2 = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown='ignore')\n",
    "if 'тип_займа' in X.columns:\n",
    "    encoded_array2 = encoder2.fit_transform(X[['тип_займа']])\n",
    "    encoded_cols2 = encoder2.get_feature_names_out(['тип_займа'])\n",
    "    train_encoded2 = pd.DataFrame(encoded_array2, columns=encoded_cols2, index=X.index)\n",
    "    X = pd.concat([X, train_encoded2], axis=1)\n",
    "    X = X.drop('тип_займа', axis=1)\n",
    "\n",
    "new_cols = {}\n",
    "if 'кол-во_ипотек' in test.columns:\n",
    "    new_cols['log_ипотек'] = np.log1p(test['кол-во_ипотек'])\n",
    "if 'кредитный_баланс_без_ипотеки' in test.columns:\n",
    "    new_cols['log_кредит_без_ипотеки'] = np.log1p(test['кредитный_баланс_без_ипотеки'])\n",
    "if 'аннуитет' in test.columns:\n",
    "    new_cols['log_аннуитет'] = np.log1p(test['аннуитет'])\n",
    "if all(c in X.columns for c in ['процентная_ставка','срок_займа','сумма_займа']):\n",
    "    new_cols['процент_ставка_срок_сумма'] = X['процентная_ставка'] * X['срок_займа'] * X['сумма_займа']\n",
    "if 'грейд_на_детерминаторе' in test.columns:\n",
    "    new_cols['грейд_на_детерминаторе'] = test['грейд_на_детерминаторе']\n",
    "if all(c in X.columns for c in ['годовой_доход','сумма_займа']):\n",
    "    new_cols['доход_к_займу'] = X['годовой_доход'] / X['сумма_займа'].replace(0, np.nan)\n",
    "\n",
    "if new_cols:\n",
    "    X = pd.concat([X, pd.DataFrame(new_cols, index=X.index)], axis=1)\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "X['log_ипотек']=X['log_ипотек'].fillna(X['log_ипотек'].median())\n",
    "X['log_кредит_без_ипотеки']=X['log_кредит_без_ипотеки'].fillna(X['log_кредит_без_ипотеки'].median())\n",
    "X['кол-во_месяцев_с_последней_карты']=X['кол-во_месяцев_с_последней_карты'].fillna(X['кол-во_месяцев_с_последней_карты'].median())\n",
    "X['кол-во_месяцев_с_последнего_возобновляемого_счета']=X['кол-во_месяцев_с_последнего_возобновляемого_счета'].fillna(X['кол-во_месяцев_с_последнего_возобновляемого_счета'].median())\n",
    "X['кол-во_открытых_счетов_за_2_года']=X['кол-во_открытых_счетов_за_2_года'].fillna(X['кол-во_открытых_счетов_за_2_года'].median())\n",
    "if 'регион' in X.columns:\n",
    "    X['регион_target_encoded'] = X['регион'].map(region_means).fillna(global_mean)\n",
    "    X['регион_freq_encoded'] = X['регион'].map(region_counts).fillna(0)\n",
    "    X = X.drop('регион', axis=1)\n",
    "\n",
    "if 'профессия_заемщика' in X.columns:\n",
    "    X = X.drop('профессия_заемщика', axis=1)\n",
    "    \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64','int32']).columns\n",
    "X = preprocessor.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07d99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame()\n",
    "test_predict = model.predict_proba(X)[:, 1]\n",
    "answer['id'] = test['id']\n",
    "answer['proba'] = test_predict\n",
    "answer.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
